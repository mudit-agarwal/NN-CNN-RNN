{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are state of the art Neural Networks that are predominantly used for Images,etc.\n",
    "\n",
    "When we normally treat an image we consider each of it's pixels and apply algorithms. But when we use CNN, we use relation pf pixels with each other as well. Like if adjoiing pixels represnt a particular objext etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How it Works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply a filter on the Image and create a new image of sorts.\n",
    "\n",
    "Let us assume we have a 20 x 20 sized image. and we run a 3 x 3 filter across it. That means we keep the 3 x 3 filter across the first pixel of the image, then the next and so on. \n",
    "\n",
    "We move the filter across all the pixels of the image. When we apply the filter on a segment of the image we do multiply each value of the filter with the corresponding value of pixel and we generate an output value like that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stride and Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stride is deciding by how much the filter has to be moved. Usually it is 1 but we can change this.\n",
    "\n",
    "Padding - zero padding or no padding is done to give corner pixels equal weightage as other pixels as corner pixels are used only once per filter unlike internal pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What to do in case of Coloured Images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coloured Images are 3-D Images of RGB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to comb through these 3-D Images we have to use a 3-D filter as well.\n",
    "\n",
    "For Example we have a 28 x 28 x 3 Image. We will need a 4 x 4 x 3 Filter to apply on it. And then we will have to have  of those for  differnet directions etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pooling layer is applied generally after every convolution layer. It helps to reduce the sizeof O/P and helps us train our NN faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width = 28\n",
    "input_height = 28\n",
    "input_channels = 1\n",
    "input_pixels = 784\n",
    "\n",
    "n_conv1 = 32\n",
    "n_conv2 = 64\n",
    "stride_conv1 = 1\n",
    "stride_conv2 = 1\n",
    "conv1_k = 5\n",
    "conv2_k = 5\n",
    "max_pool1_k = 2\n",
    "max_pool2_k = 2\n",
    "\n",
    "n_hidden = 1024\n",
    "n_out = 10\n",
    "\n",
    "input_size_to_hidden = (input_width//(max_pool1_k*max_pool2_k)) * (input_height//(max_pool1_k*max_pool2_k)) * n_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1' : tf.Variable(tf.random_normal([conv1_k, conv1_k, input_channels,n_conv1])),\n",
    "    'wc2' : tf.Variable(tf.random_normal([conv2_k,conv2_k,n_conv1,n_conv2])),\n",
    "    'wh1' : tf.Variable(tf.random_normal([input_size_to_hidden,n_hidden])),\n",
    "    'wo' : tf.Variable(tf.random_normal([n_hidden,n_out]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1' : tf.Variable(tf.random_normal([n_conv1])),\n",
    "    'bc2' : tf.Variable(tf.random_normal([n_conv2])),\n",
    "    'bh1' : tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'bo' : tf.Variable(tf.random_normal([n_out])) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x, weights, bias, strides = 1):\n",
    "    out = tf.nn.conv2d(x, weights, padding = \"SAME\", strides = [1, strides, strides, 1])\n",
    "    out = tf.nn.bias_add(out,bias)\n",
    "    out = tf.nn.relu(out)\n",
    "    return out\n",
    "\n",
    "def maxpooling(x, k=2):\n",
    "    return tf.nn.max_pool(x, padding = \"SAME\", ksize = [1,k,k,1], strides = [1,k,k,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(x,weights,biases,keep_prob):\n",
    "    x = tf.reshape(x, shape = [-1 ,input_height, input_width, input_channels])\n",
    "    conv1 = conv(x, weights['wc1'], biases['bc1'])\n",
    "    conv1_pool = maxpooling(conv1,max_pool1_k)\n",
    "    \n",
    "    conv2 = conv(conv1_pool, weights['wc2'], biases['b2'])\n",
    "    conv2_pool = maxpooling(conv2,max_pool2_k)\n",
    "    \n",
    "    hidden_input = tf.reshape(conv2_pool, shape = [-1,input_size_to_hidden])\n",
    "    hidden_output_before_activation = tf.add(tf.matmul(hidden_input, weights['wh1']), biases['bh1'])\n",
    "    hidden_output_before_dropout = tf.nn.relu(hidden_output_before_activation)\n",
    "    hidden_output = tf.nn.dropout(hidden_output_before_dropout, keep_prob)\n",
    "    \n",
    "    output = tf.add(tf.matmul(hidden_output, weights['wo']), biases['bo'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\",[None, input_pixels])\n",
    "y = tf.placeholder(tf.int32,[None, n_out])\n",
    "keep_prob = tf.placeholder[\"float\"]\n",
    "pred = cnn(x,weights,biases,keep_prob) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(f.nn.softmax_cross_entropy_with_logits_v2(logits = pred,labels =y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimzer(learning_rate = 0.01)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch-size = 100\n",
    "for i in range(25):\n",
    "    num_batches = int(mnist.train.num_examples/batch_size)\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "        c,d = sess.run([cost,optimize], feed_dict = {x:batch_x,y:batch_y, keep_prob:0.8})\n",
    "        total_cost += c\n",
    "    print(total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.argmax(pred,1)\n",
    "true_labels = tf.argmax(y,1)\n",
    "correct_predictions = tf.equal(predictions,true_labels)\n",
    "predictions_eval,labels,correct_pred = sess.run([predictions,true_labels,correct_predictions],feed_dict={x:mnist.train.images, y:mnist.train.labels, keep_prob:1.0})\n",
    "predictions_eval,labels,correct_pred\n",
    "correct_pred.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout Layer is added to avoid overfitting.\n",
    "\n",
    "It's a layer which is added in between hidden layers which gets rid of certain probabilities to avoid Overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
